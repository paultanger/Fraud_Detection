{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import Scatter, Data\n",
    "\n",
    "def plot_data(X, y):\n",
    "    '''\n",
    "    Plots 2-dimensional data containing two classes\n",
    "    '''\n",
    "    scatter0 = Scatter(x = X[:,0][y==0],\n",
    "                       y = X[:,1][y==0],\n",
    "                       mode = 'markers')\n",
    "    scatter1 = Scatter(x = X[:,0][y==1],\n",
    "                       y = X[:,1][y==1],\n",
    "                       mode = 'markers')\n",
    "    data = Data([scatter0, scatter1])   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/1314.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataset\n",
    "def generate_data(positive_qty, negative_qty):\n",
    "    '''\n",
    "    Draws from two 2-dimensional Gaussians\n",
    "    '''\n",
    "    X = np.vstack((multivariate_normal((-10, -10), \n",
    "                                       np.diag([10, 10]), \n",
    "                                       positive_qty),\n",
    "                   multivariate_normal((10, 10),\n",
    "                                       np.diag([70, 70]), \n",
    "                                       negative_qty)))\n",
    "    y = np.array([1]*positive_qty + [0]*negative_qty)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "positive_qty_train = 10\n",
    "negative_qty_train = positive_qty_train*100\n",
    "positive_qty_test = 100000\n",
    "negative_qty_test = positive_qty_test*100\n",
    "X, y = generate_data(positive_qty_train, negative_qty_train)\n",
    "X_test, y_test = generate_data(positive_qty_test, negative_qty_test)\n",
    "\n",
    "data = plot_data(X, y)\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Logistic Regression Precision 0.819887412581\n",
      "Basic Logistic Regression Recall 0.90154\n",
      "Basic Logistic Regression F1 Score 0.858777189832\n"
     ]
    }
   ],
   "source": [
    "# Basic Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "print 'Basic Logistic Regression Precision', precision_score(y_test, y_pred)\n",
    "print 'Basic Logistic Regression Recall', recall_score(y_test, y_pred)\n",
    "print \"Basic Logistic Regression F1 Score\", f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled Logistic Regression Precision 0.133007271871\n",
      "Undersampled Logistic Regression Recall 0.99995\n",
      "Undersampled Logistic Regression F1 Score 0.234784885202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/1316.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression with undersampling\n",
    "def undersample(X, y, majority_weight=.5):\n",
    "    '''\n",
    "    randomly discards observations from majority class\n",
    "    so that output X, y have specified percentage of majority observations\n",
    "    '''\n",
    "    class_ratio = y.sum()/float(len(y))\n",
    "    majority_class_label = round(class_ratio)\n",
    "    X_majority = X[y==majority_class_label]\n",
    "    y_majority = y[y==majority_class_label]\n",
    "    maj_count = len(X_majority)\n",
    "    min_count = len(X) - maj_count\n",
    "    scaling_factor = (min_count/float(maj_count))*(majority_weight/(1-majority_weight))\n",
    "    sample_indices = np.random.choice(xrange(maj_count), \n",
    "                                      size=round(maj_count*scaling_factor),\n",
    "                                      replace=False)\n",
    "    X_majority = X_majority[sample_indices]\n",
    "    y_majority = y_majority[sample_indices]\n",
    "    X = np.vstack((X_majority, X[y!=majority_class_label]))\n",
    "    y = np.hstack((y_majority, y[y!=majority_class_label]))\n",
    "    return X, y\n",
    "\n",
    "X_undersampled, y_undersampled = undersample(X, y, majority_weight=.5)\n",
    "undersampled_model = LogisticRegression()\n",
    "undersampled_model.fit(X_undersampled, y_undersampled)\n",
    "y_pred = undersampled_model.predict(X_test)\n",
    "print 'Undersampled Logistic Regression Precision', precision_score(y_test, y_pred)\n",
    "print 'Undersampled Logistic Regression Recall', recall_score(y_test, y_pred)\n",
    "print \"Undersampled Logistic Regression F1 Score\", f1_score(y_test, y_pred)\n",
    "\n",
    "data = plot_data(X_undersampled, y_undersampled)\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Logistic Regression Precision 0.500846338143\n",
      "Oversampled Logistic Regression Recall 0.99715\n",
      "Oversampled Logistic Regression F1 Score 0.666782572645\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with oversampling\n",
    "def oversample(X, y, minority_weight=.5):\n",
    "    '''\n",
    "    duplicates observations from minority class\n",
    "    so that output X, y have specified percentage of majority observations\n",
    "    '''\n",
    "    class_ratio = y.sum()/float(len(y))\n",
    "    majority_class_label = round(class_ratio)\n",
    "    X_minority = X[y!=majority_class_label]\n",
    "    y_minority = y[y!=majority_class_label]\n",
    "    min_count = len(X_minority)\n",
    "    maj_count = len(X) - min_count\n",
    "    scaling_factor = round((maj_count/float(min_count))*(minority_weight/(1-minority_weight)))\n",
    "    X_minority = np.tile(X_minority, (scaling_factor, 1))\n",
    "    y_minority = np.tile(y_minority, scaling_factor)\n",
    "    X = np.vstack((X_minority, X[y==majority_class_label]))\n",
    "    y = np.hstack((y_minority, y[y==majority_class_label]))\n",
    "    return X, y\n",
    "\n",
    "X_oversampled, y_oversampled = oversample(X, y, minority_weight=.5)\n",
    "oversampled_model = LogisticRegression()\n",
    "oversampled_model.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "y_pred = oversampled_model.predict(X_test)\n",
    "print 'Oversampled Logistic Regression Precision', precision_score(y_test, y_pred)\n",
    "print 'Oversampled Logistic Regression Recall', recall_score(y_test, y_pred)\n",
    "print \"Oversampled Logistic Regression F1 Score\", f1_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Logistic Regression Precision 0.528943398632\n",
      "SMOTE Logistic Regression Recall 0.99581\n",
      "SMOTE Logistic Regression F1 Score 0.690901395943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~michaeljancsy/1318.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression with SMOTE (Synthetic Minority Oversampling Technique)\n",
    "\n",
    "def smote(X, y, minority_weight=.5):\n",
    "    '''\n",
    "    generates new observations in minority class\n",
    "    so that output X, y have specified percentage of majority observations\n",
    "    '''\n",
    "    # compute number of new examples required\n",
    "    class_ratio = y.sum()/float(len(y))\n",
    "    majority_class_label = round(class_ratio)\n",
    "    X_minority = X[y!=majority_class_label]\n",
    "    y_minority = y[y!=majority_class_label]\n",
    "    min_count = len(X_minority)\n",
    "    maj_count = len(X) - min_count\n",
    "    scaling_factor = (maj_count/float(min_count))*(minority_weight/(1-minority_weight))\n",
    "    new_observations_target = round(scaling_factor*min_count) - min_count\n",
    "\n",
    "    # train KNN\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=int(round(len(X_minority)**.5)))\n",
    "    knn_model.fit(X_minority, y_minority)\n",
    "    if new_observations_target < len(X_minority):\n",
    "        sample_indices = np.random.choice(xrange(X_minority), \n",
    "                                          size=new_observations_target,\n",
    "                                          replace=False)\n",
    "        smote_samples = X_minority[sample_indices]\n",
    "    else:\n",
    "        smote_samples = X_minority\n",
    "    neighbors = knn_model.kneighbors(smote_samples)[1]\n",
    "    \n",
    "    # generate new samples\n",
    "    new_observations = np.empty((0,X.shape[1]))\n",
    "    while len(new_observations) < new_observations_target:\n",
    "        index = len(new_observations) % len(smote_samples)\n",
    "        neighbor_index = np.random.choice(neighbors[index])\n",
    "        neighbor = smote_samples[neighbor_index]\n",
    "        x = X_minority[index]\n",
    "        new_x = x + (neighbor - x)*np.random.random(size=X_minority.shape[1])\n",
    "        new_observations = np.vstack((new_observations, new_x))\n",
    "    minority_class_label = (majority_class_label + 1) % 2\n",
    "    X = np.vstack((X, new_observations))\n",
    "    y = np.hstack((y, np.array([minority_class_label]*len(new_observations))))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_smote, y_smote = smote(X, y, minority_weight=.5)\n",
    "smote_model = LogisticRegression()\n",
    "smote_model.fit(X_smote, y_smote)\n",
    "y_pred = smote_model.predict(X_test)\n",
    "print 'SMOTE Logistic Regression Precision', precision_score(y_test, y_pred)\n",
    "print 'SMOTE Logistic Regression Recall', recall_score(y_test, y_pred)\n",
    "print \"SMOTE Logistic Regression F1 Score\", f1_score(y_test, y_pred)\n",
    "\n",
    "data = plot_data(X_smote, y_smote)\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
